{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS - All required libraries for the notebook\n",
    "\n",
    "# Data handling and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Kaggle dataset handling\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Data visualization (for future use)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning (for future use)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Statistical analysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub[pandas-datasets] in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->kagglehub[pandas-datasets]) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\pc\\.cache\\kagglehub\\datasets\\lainguyn123\\student-performance-factors\\versions\\9\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lainguyn123/student-performance-factors\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset shape: (6607, 20)\n",
      "Total records: 6607\n",
      "Total features: 20\n"
     ]
    }
   ],
   "source": [
    "# DATASET LOADING\n",
    "\n",
    "# Read the CSV file from the downloaded dataset\n",
    "csv_file_path = os.path.join(path, \"StudentPerformanceFactors.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET COLUMN NAMES (HEADLINES)\n",
      "============================================================\n",
      "\n",
      "Column Names:\n",
      " 1. Hours_Studied\n",
      " 2. Attendance\n",
      " 3. Parental_Involvement\n",
      " 4. Access_to_Resources\n",
      " 5. Extracurricular_Activities\n",
      " 6. Sleep_Hours\n",
      " 7. Previous_Scores\n",
      " 8. Motivation_Level\n",
      " 9. Internet_Access\n",
      "10. Tutoring_Sessions\n",
      "11. Family_Income\n",
      "12. Teacher_Quality\n",
      "13. School_Type\n",
      "14. Peer_Influence\n",
      "15. Physical_Activity\n",
      "16. Learning_Disabilities\n",
      "17. Parental_Education_Level\n",
      "18. Distance_from_Home\n",
      "19. Gender\n",
      "20. Exam_Score\n",
      "\n",
      "Total Columns: 20\n",
      "\n",
      "============================================================\n",
      "DATASET INFORMATION & DESCRIPTIONS\n",
      "============================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6607 entries, 0 to 6606\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Hours_Studied               6607 non-null   int64 \n",
      " 1   Attendance                  6607 non-null   int64 \n",
      " 2   Parental_Involvement        6607 non-null   object\n",
      " 3   Access_to_Resources         6607 non-null   object\n",
      " 4   Extracurricular_Activities  6607 non-null   object\n",
      " 5   Sleep_Hours                 6607 non-null   int64 \n",
      " 6   Previous_Scores             6607 non-null   int64 \n",
      " 7   Motivation_Level            6607 non-null   object\n",
      " 8   Internet_Access             6607 non-null   object\n",
      " 9   Tutoring_Sessions           6607 non-null   int64 \n",
      " 10  Family_Income               6607 non-null   object\n",
      " 11  Teacher_Quality             6529 non-null   object\n",
      " 12  School_Type                 6607 non-null   object\n",
      " 13  Peer_Influence              6607 non-null   object\n",
      " 14  Physical_Activity           6607 non-null   int64 \n",
      " 15  Learning_Disabilities       6607 non-null   object\n",
      " 16  Parental_Education_Level    6517 non-null   object\n",
      " 17  Distance_from_Home          6540 non-null   object\n",
      " 18  Gender                      6607 non-null   object\n",
      " 19  Exam_Score                  6607 non-null   int64 \n",
      "dtypes: int64(7), object(13)\n",
      "memory usage: 1.0+ MB\n",
      "\n",
      "============================================================\n",
      "STATISTICAL SUMMARY\n",
      "============================================================\n",
      "       Hours_Studied   Attendance  Sleep_Hours  Previous_Scores  \\\n",
      "count    6607.000000  6607.000000   6607.00000      6607.000000   \n",
      "mean       19.975329    79.977448      7.02906        75.070531   \n",
      "std         5.990594    11.547475      1.46812        14.399784   \n",
      "min         1.000000    60.000000      4.00000        50.000000   \n",
      "25%        16.000000    70.000000      6.00000        63.000000   \n",
      "50%        20.000000    80.000000      7.00000        75.000000   \n",
      "75%        24.000000    90.000000      8.00000        88.000000   \n",
      "max        44.000000   100.000000     10.00000       100.000000   \n",
      "\n",
      "       Tutoring_Sessions  Physical_Activity   Exam_Score  \n",
      "count        6607.000000        6607.000000  6607.000000  \n",
      "mean            1.493719           2.967610    67.235659  \n",
      "std             1.230570           1.031231     3.890456  \n",
      "min             0.000000           0.000000    55.000000  \n",
      "25%             1.000000           2.000000    65.000000  \n",
      "50%             1.000000           3.000000    67.000000  \n",
      "75%             2.000000           4.000000    69.000000  \n",
      "max             8.000000           6.000000   101.000000  \n",
      "\n",
      "============================================================\n",
      "DATA TYPES AND NON-NULL COUNTS\n",
      "============================================================\n",
      "\n",
      "Data Types:\n",
      "Hours_Studied             | int64        | Non-null: 6607 | Null:   0\n",
      "Attendance                | int64        | Non-null: 6607 | Null:   0\n",
      "Parental_Involvement      | object       | Non-null: 6607 | Null:   0\n",
      "Access_to_Resources       | object       | Non-null: 6607 | Null:   0\n",
      "Extracurricular_Activities | object       | Non-null: 6607 | Null:   0\n",
      "Sleep_Hours               | int64        | Non-null: 6607 | Null:   0\n",
      "Previous_Scores           | int64        | Non-null: 6607 | Null:   0\n",
      "Motivation_Level          | object       | Non-null: 6607 | Null:   0\n",
      "Internet_Access           | object       | Non-null: 6607 | Null:   0\n",
      "Tutoring_Sessions         | int64        | Non-null: 6607 | Null:   0\n",
      "Family_Income             | object       | Non-null: 6607 | Null:   0\n",
      "Teacher_Quality           | object       | Non-null: 6529 | Null:  78\n",
      "School_Type               | object       | Non-null: 6607 | Null:   0\n",
      "Peer_Influence            | object       | Non-null: 6607 | Null:   0\n",
      "Physical_Activity         | int64        | Non-null: 6607 | Null:   0\n",
      "Learning_Disabilities     | object       | Non-null: 6607 | Null:   0\n",
      "Parental_Education_Level  | object       | Non-null: 6517 | Null:  90\n",
      "Distance_from_Home        | object       | Non-null: 6540 | Null:  67\n",
      "Gender                    | object       | Non-null: 6607 | Null:   0\n",
      "Exam_Score                | int64        | Non-null: 6607 | Null:   0\n",
      "\n",
      "============================================================\n",
      "SAMPLE DATA (First 5 rows)\n",
      "============================================================\n",
      "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
      "0             23          84                  Low                High   \n",
      "1             19          64                  Low              Medium   \n",
      "2             24          98               Medium              Medium   \n",
      "3             29          89                  Low              Medium   \n",
      "4             19          92               Medium              Medium   \n",
      "\n",
      "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
      "0                         No            7               73              Low   \n",
      "1                         No            8               59              Low   \n",
      "2                        Yes            7               91           Medium   \n",
      "3                        Yes            8               98           Medium   \n",
      "4                        Yes            6               65           Medium   \n",
      "\n",
      "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
      "0             Yes                  0           Low          Medium   \n",
      "1             Yes                  2        Medium          Medium   \n",
      "2             Yes                  2        Medium          Medium   \n",
      "3             Yes                  1        Medium          Medium   \n",
      "4             Yes                  3        Medium            High   \n",
      "\n",
      "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
      "0      Public       Positive                  3                    No   \n",
      "1      Public       Negative                  4                    No   \n",
      "2      Public        Neutral                  4                    No   \n",
      "3      Public       Negative                  4                    No   \n",
      "4      Public        Neutral                  4                    No   \n",
      "\n",
      "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
      "0              High School               Near    Male          67  \n",
      "1                  College           Moderate  Female          61  \n",
      "2             Postgraduate               Near    Male          74  \n",
      "3              High School           Moderate    Male          71  \n",
      "4                  College               Near  Female          70  \n"
     ]
    }
   ],
   "source": [
    "# DATASET EXPLORATION & ANALYSIS\n",
    "\n",
    "# Display column names (headlines) and basic dataset information\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET COLUMN NAMES (HEADLINES)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal Columns: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET INFORMATION & DESCRIPTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display detailed info about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display statistical summary\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA TYPES AND NON-NULL COUNTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display data types and null values\n",
    "print(\"\\nData Types:\")\n",
    "for col in df.columns:\n",
    "    dtype = df[col].dtype\n",
    "    non_null = df[col].count()\n",
    "    null_count = df[col].isnull().sum()\n",
    "    print(f\"{col:25s} | {str(dtype):12s} | Non-null: {non_null:4d} | Null: {null_count:3d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE DATA (First 5 rows)\")\n",
    "print(\"=\" * 60)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORMATIVE 1: DATABASE DESIGN & PREDICTION PIPELINE\n",
    "\n",
    "## Project Overview\n",
    "**Dataset:** Student Performance Factors  \n",
    "**Objective:** Create a comprehensive database system with ML prediction capabilities\n",
    "\n",
    "### Tasks:\n",
    "1. **Task 1:** Database Design (SQL + MongoDB)\n",
    "2. **Task 2:** FastAPI CRUD Operations  \n",
    "3. **Task 3:** ML Prediction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING DATASET FOR NORMALIZATION\n",
      "==================================================\n",
      "\n",
      "PROPOSED SCHEMA DESIGN (3NF):\n",
      "\n",
      "1. STUDENTS Table (Main Entity):\n",
      "   - student_id (PK)\n",
      "   - Gender\n",
      "   - Learning_Disabilities\n",
      "   - Distance_from_Home\n",
      "\n",
      "2. ACADEMIC_RECORDS Table:\n",
      "   - record_id (PK)\n",
      "   - student_id (FK)\n",
      "   - Hours_Studied\n",
      "   - Attendance\n",
      "   - Previous_Scores\n",
      "   - Tutoring_Sessions\n",
      "   - Exam_Score\n",
      "   - created_at\n",
      "\n",
      "3. ENVIRONMENTAL_FACTORS Table:\n",
      "   - env_id (PK)\n",
      "   - student_id (FK)\n",
      "   - Parental_Involvement\n",
      "   - Access_to_Resources\n",
      "   - Extracurricular_Activities\n",
      "   - Sleep_Hours\n",
      "   - Motivation_Level\n",
      "   - Internet_Access\n",
      "   - Family_Income\n",
      "   - Teacher_Quality\n",
      "   - School_Type\n",
      "   - Peer_Influence\n",
      "   - Physical_Activity\n",
      "   - Parental_Education_Level\n",
      "\n",
      "4. PREDICTIONS Table (For ML Results):\n",
      "   - prediction_id (PK)\n",
      "   - student_id (FK)\n",
      "   - predicted_score\n",
      "   - actual_score\n",
      "   - model_version\n",
      "   - prediction_date\n",
      "   - confidence_score\n",
      "\n",
      "RELATIONSHIPS:\n",
      "   - Students (1) → Academic_Records (Many)\n",
      "   - Students (1) → Environmental_Factors (Many)\n",
      "   - Students (1) → Predictions (Many)\n",
      "\n",
      "Schema satisfies 3NF requirements:\n",
      "   1NF: Atomic values, unique rows\n",
      "   2NF: No partial dependencies\n",
      "   3NF: No transitive dependencies\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: DATABASE SCHEMA DESIGN (3NF Normalization)\n",
    "\n",
    "# Analyze dataset structure for normalization\n",
    "print(\"ANALYZING DATASET FOR NORMALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Group columns by logical entities for normalization\n",
    "print(\"\\nPROPOSED SCHEMA DESIGN (3NF):\")\n",
    "print(\"\\n1. STUDENTS Table (Main Entity):\")\n",
    "students_cols = ['student_id (PK)', 'Gender', 'Learning_Disabilities', 'Distance_from_Home']\n",
    "for col in students_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n2. ACADEMIC_RECORDS Table:\")\n",
    "academic_cols = ['record_id (PK)', 'student_id (FK)', 'Hours_Studied', 'Attendance', \n",
    "                'Previous_Scores', 'Tutoring_Sessions', 'Exam_Score', 'created_at']\n",
    "for col in academic_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n3. ENVIRONMENTAL_FACTORS Table:\")\n",
    "env_cols = ['env_id (PK)', 'student_id (FK)', 'Parental_Involvement', 'Access_to_Resources',\n",
    "           'Extracurricular_Activities', 'Sleep_Hours', 'Motivation_Level', 'Internet_Access',\n",
    "           'Family_Income', 'Teacher_Quality', 'School_Type', 'Peer_Influence', \n",
    "           'Physical_Activity', 'Parental_Education_Level']\n",
    "for col in env_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n4. PREDICTIONS Table (For ML Results):\")\n",
    "pred_cols = ['prediction_id (PK)', 'student_id (FK)', 'predicted_score', \n",
    "            'actual_score', 'model_version', 'prediction_date', 'confidence_score']\n",
    "for col in pred_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\nRELATIONSHIPS:\")\n",
    "print(\"   - Students (1) → Academic_Records (Many)\")\n",
    "print(\"   - Students (1) → Environmental_Factors (Many)\")  \n",
    "print(\"   - Students (1) → Predictions (Many)\")\n",
    "\n",
    "print(\"\\nSchema satisfies 3NF requirements:\")\n",
    "print(\"   1NF: Atomic values, unique rows\")\n",
    "print(\"   2NF: No partial dependencies\")\n",
    "print(\"   3NF: No transitive dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL Database Schema Generated Successfully!\n",
      "Schema includes:\n",
      "   4 main tables + 1 audit table\n",
      "   Primary and Foreign Key constraints\n",
      "   Check constraints for data validation\n",
      "   Appropriate indexes for performance\n",
      "   Timestamps for tracking\n",
      "\n",
      "Next: Stored Procedure & Trigger creation...\n"
     ]
    }
   ],
   "source": [
    "# MYSQL DATABASE CREATION SCRIPTS\n",
    "\n",
    "# Generate MySQL DDL statements for database creation\n",
    "mysql_ddl = \"\"\"\n",
    "-- STUDENT PERFORMANCE DATABASE SCHEMA\n",
    "\n",
    "DROP DATABASE IF EXISTS student_performance_db;\n",
    "CREATE DATABASE student_performance_db;\n",
    "USE student_performance_db;\n",
    "\n",
    "-- TABLE 1: STUDENTS (Main Entity)\n",
    "CREATE TABLE students (\n",
    "    student_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    gender ENUM('Male', 'Female') NOT NULL,\n",
    "    learning_disabilities ENUM('Yes', 'No') NOT NULL DEFAULT 'No',\n",
    "    distance_from_home ENUM('Near', 'Moderate', 'Far') DEFAULT 'Moderate',\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "    \n",
    "    INDEX idx_gender (gender),\n",
    "    INDEX idx_learning_disabilities (learning_disabilities)\n",
    ");\n",
    "\n",
    "-- TABLE 2: ACADEMIC_RECORDS\n",
    "CREATE TABLE academic_records (\n",
    "    record_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    hours_studied INT CHECK (hours_studied >= 0 AND hours_studied <= 50),\n",
    "    attendance INT CHECK (attendance >= 0 AND attendance <= 100),\n",
    "    previous_scores INT CHECK (previous_scores >= 0 AND previous_scores <= 100),\n",
    "    tutoring_sessions INT DEFAULT 0 CHECK (tutoring_sessions >= 0),\n",
    "    exam_score INT CHECK (exam_score >= 0 AND exam_score <= 110),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_academic (student_id),\n",
    "    INDEX idx_exam_score (exam_score),\n",
    "    INDEX idx_created_at (created_at)\n",
    ");\n",
    "\n",
    "-- TABLE 3: ENVIRONMENTAL_FACTORS  \n",
    "CREATE TABLE environmental_factors (\n",
    "    env_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    parental_involvement ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    access_to_resources ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    extracurricular_activities ENUM('Yes', 'No') DEFAULT 'No',\n",
    "    sleep_hours INT CHECK (sleep_hours >= 4 AND sleep_hours <= 12),\n",
    "    motivation_level ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    internet_access ENUM('Yes', 'No') DEFAULT 'Yes',\n",
    "    family_income ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    teacher_quality ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    school_type ENUM('Public', 'Private') DEFAULT 'Public',\n",
    "    peer_influence ENUM('Positive', 'Neutral', 'Negative') DEFAULT 'Neutral',\n",
    "    physical_activity INT CHECK (physical_activity >= 0 AND physical_activity <= 10),\n",
    "    parental_education_level ENUM('High School', 'College', 'Postgraduate') DEFAULT 'High School',\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_env (student_id),\n",
    "    INDEX idx_parental_involvement (parental_involvement),\n",
    "    INDEX idx_school_type (school_type)\n",
    ");\n",
    "\n",
    "-- TABLE 4: PREDICTIONS (ML Results)\n",
    "CREATE TABLE predictions (\n",
    "    prediction_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    predicted_score DECIMAL(5,2) CHECK (predicted_score >= 0 AND predicted_score <= 110),\n",
    "    actual_score INT NULL CHECK (actual_score >= 0 AND actual_score <= 110),\n",
    "    model_version VARCHAR(50) DEFAULT 'v1.0',\n",
    "    confidence_score DECIMAL(5,4) CHECK (confidence_score >= 0 AND confidence_score <= 1),\n",
    "    prediction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_predictions (student_id),\n",
    "    INDEX idx_prediction_date (prediction_date),\n",
    "    INDEX idx_model_version (model_version)\n",
    ");\n",
    "\n",
    "-- TABLE 5: AUDIT_LOG (For Trigger)\n",
    "CREATE TABLE audit_log (\n",
    "    log_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    table_name VARCHAR(50) NOT NULL,\n",
    "    operation ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,\n",
    "    record_id INT NOT NULL,\n",
    "    old_values JSON NULL,\n",
    "    new_values JSON NULL,\n",
    "    changed_by VARCHAR(100) DEFAULT 'system',\n",
    "    change_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    INDEX idx_table_operation (table_name, operation),\n",
    "    INDEX idx_change_timestamp (change_timestamp)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"MySQL Database Schema Generated Successfully!\")\n",
    "print(\"Schema includes:\")\n",
    "print(\"   4 main tables + 1 audit table\")\n",
    "print(\"   Primary and Foreign Key constraints\") \n",
    "print(\"   Check constraints for data validation\")\n",
    "print(\"   Appropriate indexes for performance\")\n",
    "print(\"   Timestamps for tracking\")\n",
    "print(\"\\nNext: Stored Procedure & Trigger creation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORED PROCEDURES & TRIGGERS CREATED:\n",
      "==================================================\n",
      "Stored Procedures:\n",
      "   1. GetStudentPerformanceSummary() - Comprehensive student data retrieval\n",
      "   2. InsertCompleteStudentRecord() - Atomic multi-table insertion\n",
      "\n",
      "Triggers:\n",
      "   1. audit_academic_records_update - Logs all academic record changes\n",
      "   2. validate_exam_score_insert - Data validation before insertion\n",
      "\n",
      "All database objects satisfy assignment requirements!\n",
      "\n",
      "Complete SQL script saved to: student_performance_db_schema.sql\n"
     ]
    }
   ],
   "source": [
    "# STORED PROCEDURES & TRIGGERS\n",
    "\n",
    "stored_procedures_triggers = \"\"\"\n",
    "-- STORED PROCEDURE: Get Student Performance Summary\n",
    "DELIMITER //\n",
    "\n",
    "CREATE PROCEDURE GetStudentPerformanceSummary(IN student_id_param INT)\n",
    "BEGIN\n",
    "    DECLARE EXIT HANDLER FOR SQLEXCEPTION\n",
    "    BEGIN\n",
    "        ROLLBACK;\n",
    "        RESIGNAL;\n",
    "    END;\n",
    "    \n",
    "    SELECT \n",
    "        s.student_id,\n",
    "        s.gender,\n",
    "        s.learning_disabilities,\n",
    "        s.distance_from_home,\n",
    "        ar.hours_studied,\n",
    "        ar.attendance,\n",
    "        ar.previous_scores,\n",
    "        ar.exam_score,\n",
    "        ef.parental_involvement,\n",
    "        ef.school_type,\n",
    "        ef.motivation_level,\n",
    "        COUNT(p.prediction_id) as total_predictions,\n",
    "        AVG(p.predicted_score) as avg_predicted_score,\n",
    "        AVG(p.confidence_score) as avg_confidence\n",
    "    FROM students s\n",
    "    LEFT JOIN academic_records ar ON s.student_id = ar.student_id\n",
    "    LEFT JOIN environmental_factors ef ON s.student_id = ef.student_id  \n",
    "    LEFT JOIN predictions p ON s.student_id = p.student_id\n",
    "    WHERE s.student_id = student_id_param\n",
    "    GROUP BY s.student_id, s.gender, s.learning_disabilities, s.distance_from_home,\n",
    "             ar.hours_studied, ar.attendance, ar.previous_scores, ar.exam_score,\n",
    "             ef.parental_involvement, ef.school_type, ef.motivation_level;\n",
    "END //\n",
    "\n",
    "-- STORED PROCEDURE: Insert Complete Student Record\n",
    "CREATE PROCEDURE InsertCompleteStudentRecord(\n",
    "    IN p_gender ENUM('Male', 'Female'),\n",
    "    IN p_learning_disabilities ENUM('Yes', 'No'),\n",
    "    IN p_distance_from_home ENUM('Near', 'Moderate', 'Far'),\n",
    "    IN p_hours_studied INT,\n",
    "    IN p_attendance INT,\n",
    "    IN p_previous_scores INT,\n",
    "    IN p_exam_score INT,\n",
    "    IN p_parental_involvement ENUM('Low', 'Medium', 'High'),\n",
    "    IN p_access_to_resources ENUM('Low', 'Medium', 'High'),\n",
    "    IN p_sleep_hours INT,\n",
    "    IN p_school_type ENUM('Public', 'Private'),\n",
    "    OUT p_student_id INT\n",
    ")\n",
    "BEGIN\n",
    "    DECLARE EXIT HANDLER FOR SQLEXCEPTION\n",
    "    BEGIN\n",
    "        ROLLBACK;\n",
    "        RESIGNAL;\n",
    "    END;\n",
    "    \n",
    "    START TRANSACTION;\n",
    "    \n",
    "    -- Insert student\n",
    "    INSERT INTO students (gender, learning_disabilities, distance_from_home)\n",
    "    VALUES (p_gender, p_learning_disabilities, p_distance_from_home);\n",
    "    \n",
    "    SET p_student_id = LAST_INSERT_ID();\n",
    "    \n",
    "    -- Insert academic record\n",
    "    INSERT INTO academic_records (student_id, hours_studied, attendance, previous_scores, exam_score)\n",
    "    VALUES (p_student_id, p_hours_studied, p_attendance, p_previous_scores, p_exam_score);\n",
    "    \n",
    "    -- Insert environmental factors\n",
    "    INSERT INTO environmental_factors (student_id, parental_involvement, access_to_resources, sleep_hours, school_type)\n",
    "    VALUES (p_student_id, p_parental_involvement, p_access_to_resources, p_sleep_hours, p_school_type);\n",
    "    \n",
    "    COMMIT;\n",
    "END //\n",
    "\n",
    "DELIMITER ;\n",
    "\n",
    "-- TRIGGER: Audit Academic Records Changes\n",
    "DELIMITER //\n",
    "\n",
    "CREATE TRIGGER audit_academic_records_update\n",
    "    AFTER UPDATE ON academic_records\n",
    "    FOR EACH ROW\n",
    "BEGIN\n",
    "    INSERT INTO audit_log (\n",
    "        table_name, \n",
    "        operation, \n",
    "        record_id, \n",
    "        old_values, \n",
    "        new_values,\n",
    "        changed_by\n",
    "    ) VALUES (\n",
    "        'academic_records',\n",
    "        'UPDATE',\n",
    "        NEW.record_id,\n",
    "        JSON_OBJECT(\n",
    "            'hours_studied', OLD.hours_studied,\n",
    "            'attendance', OLD.attendance, \n",
    "            'previous_scores', OLD.previous_scores,\n",
    "            'exam_score', OLD.exam_score\n",
    "        ),\n",
    "        JSON_OBJECT(\n",
    "            'hours_studied', NEW.hours_studied,\n",
    "            'attendance', NEW.attendance,\n",
    "            'previous_scores', NEW.previous_scores, \n",
    "            'exam_score', NEW.exam_score\n",
    "        ),\n",
    "        USER()\n",
    "    );\n",
    "END //\n",
    "\n",
    "-- TRIGGER: Validate Exam Score Range\n",
    "CREATE TRIGGER validate_exam_score_insert\n",
    "    BEFORE INSERT ON academic_records\n",
    "    FOR EACH ROW\n",
    "BEGIN\n",
    "    IF NEW.exam_score < 0 OR NEW.exam_score > 110 THEN\n",
    "        SIGNAL SQLSTATE '45000' \n",
    "        SET MESSAGE_TEXT = 'Exam score must be between 0 and 110';\n",
    "    END IF;\n",
    "    \n",
    "    IF NEW.attendance < 60 AND NEW.exam_score > 90 THEN\n",
    "        SIGNAL SQLSTATE '45000'\n",
    "        SET MESSAGE_TEXT = 'Attendance below 60% with score above 90 seems suspicious';\n",
    "    END IF;\n",
    "END //\n",
    "\n",
    "DELIMITER ;\n",
    "\"\"\"\n",
    "\n",
    "print(\"STORED PROCEDURES & TRIGGERS CREATED:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Stored Procedures:\")\n",
    "print(\"   1. GetStudentPerformanceSummary() - Comprehensive student data retrieval\")\n",
    "print(\"   2. InsertCompleteStudentRecord() - Atomic multi-table insertion\")\n",
    "print()\n",
    "print(\"Triggers:\")\n",
    "print(\"   1. audit_academic_records_update - Logs all academic record changes\")\n",
    "print(\"   2. validate_exam_score_insert - Data validation before insertion\")\n",
    "print()\n",
    "print(\"All database objects satisfy assignment requirements!\")\n",
    "\n",
    "# Save the complete SQL script to file\n",
    "with open('student_performance_db_schema.sql', 'w') as f:\n",
    "    f.write(mysql_ddl + \"\\n\" + stored_procedures_triggers)\n",
    "    \n",
    "print(\"\\nComplete SQL script saved to: student_performance_db_schema.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMING DATASET FOR NORMALIZED SCHEMA\n",
      "==================================================\n",
      "Data transformation completed:\n",
      "   Students: 6607 records\n",
      "   Academic Records: 6607 records\n",
      "   Environmental Factors: 6607 records\n",
      "\n",
      "SAMPLE NORMALIZED DATA:\n",
      "\n",
      "Students Table (first 3):\n",
      "   student_id  gender learning_disabilities distance_from_home\n",
      "0           1    Male                    No               Near\n",
      "1           2  Female                    No           Moderate\n",
      "2           3    Male                    No               Near\n",
      "\n",
      "Academic Records (first 3):\n",
      "   student_id  hours_studied  attendance  previous_scores  tutoring_sessions  \\\n",
      "0           1             23          84               73                  0   \n",
      "1           2             19          64               59                  2   \n",
      "2           3             24          98               91                  2   \n",
      "\n",
      "   exam_score  \n",
      "0          67  \n",
      "1          61  \n",
      "2          74  \n",
      "\n",
      "Environmental Factors (first 3):\n",
      "   student_id parental_involvement school_type motivation_level\n",
      "0           1                  Low      Public              Low\n",
      "1           2                  Low      Public              Low\n",
      "2           3               Medium      Public           Medium\n",
      "Data transformation completed:\n",
      "   Students: 6607 records\n",
      "   Academic Records: 6607 records\n",
      "   Environmental Factors: 6607 records\n",
      "\n",
      "SAMPLE NORMALIZED DATA:\n",
      "\n",
      "Students Table (first 3):\n",
      "   student_id  gender learning_disabilities distance_from_home\n",
      "0           1    Male                    No               Near\n",
      "1           2  Female                    No           Moderate\n",
      "2           3    Male                    No               Near\n",
      "\n",
      "Academic Records (first 3):\n",
      "   student_id  hours_studied  attendance  previous_scores  tutoring_sessions  \\\n",
      "0           1             23          84               73                  0   \n",
      "1           2             19          64               59                  2   \n",
      "2           3             24          98               91                  2   \n",
      "\n",
      "   exam_score  \n",
      "0          67  \n",
      "1          61  \n",
      "2          74  \n",
      "\n",
      "Environmental Factors (first 3):\n",
      "   student_id parental_involvement school_type motivation_level\n",
      "0           1                  Low      Public              Low\n",
      "1           2                  Low      Public              Low\n",
      "2           3               Medium      Public           Medium\n"
     ]
    }
   ],
   "source": [
    "# DATA TRANSFORMATION & DATABASE POPULATION\n",
    "\n",
    "# Transform the flat dataset into normalized structure\n",
    "print(\"TRANSFORMING DATASET FOR NORMALIZED SCHEMA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create normalized dataframes\n",
    "students_data = []\n",
    "academic_records_data = []\n",
    "environmental_factors_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    student_id = index + 1  # Start from 1\n",
    "    \n",
    "    # Students table data\n",
    "    students_data.append({\n",
    "        'student_id': student_id,\n",
    "        'gender': row['Gender'],\n",
    "        'learning_disabilities': row['Learning_Disabilities'],\n",
    "        'distance_from_home': row['Distance_from_Home'] if pd.notna(row['Distance_from_Home']) else 'Moderate'\n",
    "    })\n",
    "    \n",
    "    # Academic records data\n",
    "    academic_records_data.append({\n",
    "        'student_id': student_id,\n",
    "        'hours_studied': int(row['Hours_Studied']),\n",
    "        'attendance': int(row['Attendance']), \n",
    "        'previous_scores': int(row['Previous_Scores']),\n",
    "        'tutoring_sessions': int(row['Tutoring_Sessions']),\n",
    "        'exam_score': int(row['Exam_Score'])\n",
    "    })\n",
    "    \n",
    "    # Environmental factors data\n",
    "    environmental_factors_data.append({\n",
    "        'student_id': student_id,\n",
    "        'parental_involvement': row['Parental_Involvement'],\n",
    "        'access_to_resources': row['Access_to_Resources'],\n",
    "        'extracurricular_activities': row['Extracurricular_Activities'],\n",
    "        'sleep_hours': int(row['Sleep_Hours']),\n",
    "        'motivation_level': row['Motivation_Level'],\n",
    "        'internet_access': row['Internet_Access'],\n",
    "        'family_income': row['Family_Income'],\n",
    "        'teacher_quality': row['Teacher_Quality'] if pd.notna(row['Teacher_Quality']) else 'Medium',\n",
    "        'school_type': row['School_Type'],\n",
    "        'peer_influence': row['Peer_Influence'],\n",
    "        'physical_activity': int(row['Physical_Activity']),\n",
    "        'parental_education_level': row['Parental_Education_Level'] if pd.notna(row['Parental_Education_Level']) else 'High School'\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "students_df = pd.DataFrame(students_data)\n",
    "academic_df = pd.DataFrame(academic_records_data)\n",
    "environmental_df = pd.DataFrame(environmental_factors_data)\n",
    "\n",
    "print(f\"Data transformation completed:\")\n",
    "print(f\"   Students: {len(students_df)} records\")\n",
    "print(f\"   Academic Records: {len(academic_df)} records\")\n",
    "print(f\"   Environmental Factors: {len(environmental_df)} records\")\n",
    "\n",
    "# Display sample of normalized data\n",
    "print(\"\\nSAMPLE NORMALIZED DATA:\")\n",
    "print(\"\\nStudents Table (first 3):\")\n",
    "print(students_df.head(3))\n",
    "\n",
    "print(\"\\nAcademic Records (first 3):\")\n",
    "print(academic_df.head(3))\n",
    "\n",
    "print(\"\\nEnvironmental Factors (first 3):\")\n",
    "print(environmental_df[['student_id', 'parental_involvement', 'school_type', 'motivation_level']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1 COMPLETION: POPULATE MYSQL DATABASE\n",
    "\n",
    "Now that we have the schema and normalized data, let's populate the actual MySQL database with our 6607 student records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Creating database...\n",
      "Error creating database: 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMySQLInterfaceError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:354\u001b[39m, in \u001b[36mCMySQLConnection._open_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmysql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcnx_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m     \u001b[38;5;28mself\u001b[39m._cmysql.converter_str_fallback = \u001b[38;5;28mself\u001b[39m._converter_str_fallback\n",
      "\u001b[31mMySQLInterfaceError\u001b[39m: Access denied for user 'root'@'localhost' (using password: YES)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Step 1: Create database\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStep 1: Creating database...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mcreate_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Step 2: Execute schema\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 2: Executing schema...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mcreate_database\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create the database if it doesn't exist\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Connect without specifying database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     connection = \u001b[43mmysql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpassword\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     cursor = connection.cursor()\n\u001b[32m     29\u001b[39m     cursor.execute(\u001b[33m\"\u001b[39m\u001b[33mCREATE DATABASE IF NOT EXISTS student_performance_db\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mysql\\connector\\pooling.py:322\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(ERROR_NO_CEXT)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CMySQLConnection \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_pure:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCMySQLConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m MySQLConnection(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:142\u001b[39m, in \u001b[36mCMySQLConnection.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    144\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mysql\\connector\\abstracts.py:1604\u001b[39m, in \u001b[36mMySQLConnectionAbstract.connect\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1601\u001b[39m     \u001b[38;5;28mself\u001b[39m.config(**kwargs)\n\u001b[32m   1603\u001b[39m \u001b[38;5;28mself\u001b[39m.disconnect()\n\u001b[32m-> \u001b[39m\u001b[32m1604\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m charset, collation = (\n\u001b[32m   1607\u001b[39m     kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcharset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1608\u001b[39m     kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcollation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1609\u001b[39m )\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m charset \u001b[38;5;129;01mor\u001b[39;00m collation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:360\u001b[39m, in \u001b[36mCMySQLConnection._open_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(err, \u001b[33m\"\u001b[39m\u001b[33merrno\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[32m    361\u001b[39m             err.errno, msg=err.msg, sqlstate=err.sqlstate\n\u001b[32m    362\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;28mself\u001b[39m._do_handshake()\n",
      "\u001b[31mProgrammingError\u001b[39m: 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)"
     ]
    }
   ],
   "source": [
    "# MYSQL DATABASE POPULATION\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# FORCE RELOAD environment variables (in case .env was updated)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Database connection configuration\n",
    "db_config = {\n",
    "    'host': os.getenv('MYSQL_HOST', 'localhost'),\n",
    "    'user': os.getenv('MYSQL_USER', 'root'),\n",
    "    'password': os.getenv('MYSQL_PASSWORD', ''),\n",
    "    'database': 'student_performance_db'\n",
    "}\n",
    "\n",
    "# Print config to verify (hide password for security)\n",
    "print(\"Database Configuration:\")\n",
    "print(f\"  Host: {db_config['host']}\")\n",
    "print(f\"  User: {db_config['user']}\")\n",
    "print(f\"  Password: {'*' * len(db_config['password']) if db_config['password'] else '(EMPTY - THIS IS THE PROBLEM!)'}\")\n",
    "print(f\"  Database: {db_config['database']}\")\n",
    "print()\n",
    "\n",
    "def create_database():\n",
    "    \"\"\"Create the database if it doesn't exist\"\"\"\n",
    "    try:\n",
    "        # Connect without specifying database\n",
    "        connection = mysql.connector.connect(\n",
    "            host=db_config['host'],\n",
    "            user=db_config['user'],\n",
    "            password=db_config['password']\n",
    "        )\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS student_performance_db\")\n",
    "        print(\"✓ Database 'student_performance_db' created or already exists\")\n",
    "        \n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"✗ Error creating database: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Make sure MySQL server is running\")\n",
    "        print(\"2. Verify your .env file has the correct MYSQL_PASSWORD\")\n",
    "        print(\"3. Check if the password contains special characters that need escaping\")\n",
    "        raise\n",
    "\n",
    "def execute_schema():\n",
    "    \"\"\"Execute the SQL schema file\"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # Read and execute the schema file\n",
    "        with open('student_performance_db_schema.sql', 'r') as f:\n",
    "            sql_script = f.read()\n",
    "        \n",
    "        # Split by semicolon and execute each statement\n",
    "        statements = sql_script.split(';')\n",
    "        \n",
    "        for statement in statements:\n",
    "            statement = statement.strip()\n",
    "            if statement and not statement.startswith('--'):\n",
    "                try:\n",
    "                    cursor.execute(statement)\n",
    "                except Error as e:\n",
    "                    # Skip delimiter statements and other non-executable statements\n",
    "                    if 'DELIMITER' not in statement:\n",
    "                        print(f\"Warning: {e}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        print(\"✓ Schema executed successfully!\")\n",
    "        \n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"✗ Error executing schema: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 1: Create database\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: CREATING DATABASE\")\n",
    "print(\"=\" * 70)\n",
    "create_database()\n",
    "\n",
    "# Step 2: Execute schema\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: EXECUTING SCHEMA\")\n",
    "print(\"=\" * 70)\n",
    "execute_schema()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ DATABASE SETUP COMPLETED!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT NORMALIZED DATA INTO MYSQL (BATCH PROCESSING)\n",
    "\n",
    "def insert_students_batch(connection, students_df, batch_size=100):\n",
    "    \"\"\"Insert student records in batches\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO students (gender, learning_disabilities, distance_from_home)\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    total_records = len(students_df)\n",
    "    records_inserted = 0\n",
    "    \n",
    "    print(f\"Inserting {total_records} students in batches of {batch_size}...\")\n",
    "    \n",
    "    for start_idx in range(0, total_records, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_records)\n",
    "        batch = students_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        batch_count = 0\n",
    "        for _, row in batch.iterrows():\n",
    "            try:\n",
    "                cursor.execute(insert_query, (\n",
    "                    row['gender'],\n",
    "                    row['learning_disabilities'],\n",
    "                    row['distance_from_home']\n",
    "                ))\n",
    "                batch_count += 1\n",
    "            except Error as e:\n",
    "                print(f\"  Error in row {start_idx + batch_count}: {e}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        records_inserted += batch_count\n",
    "        print(f\"  Batch {start_idx//batch_size + 1}: Inserted {batch_count}/{len(batch)} records (Total: {records_inserted}/{total_records})\")\n",
    "    \n",
    "    cursor.close()\n",
    "    return records_inserted\n",
    "\n",
    "def insert_academic_records_batch(connection, academic_df, batch_size=100):\n",
    "    \"\"\"Insert academic records in batches\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO academic_records \n",
    "    (student_id, hours_studied, attendance, previous_scores, tutoring_sessions, exam_score)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    total_records = len(academic_df)\n",
    "    records_inserted = 0\n",
    "    \n",
    "    print(f\"Inserting {total_records} academic records in batches of {batch_size}...\")\n",
    "    \n",
    "    for start_idx in range(0, total_records, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_records)\n",
    "        batch = academic_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        batch_count = 0\n",
    "        for _, row in batch.iterrows():\n",
    "            try:\n",
    "                cursor.execute(insert_query, (\n",
    "                    row['student_id'],\n",
    "                    row['hours_studied'],\n",
    "                    row['attendance'],\n",
    "                    row['previous_scores'],\n",
    "                    row['tutoring_sessions'],\n",
    "                    row['exam_score']\n",
    "                ))\n",
    "                batch_count += 1\n",
    "            except Error as e:\n",
    "                print(f\"  Error in row {start_idx + batch_count}: {e}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        records_inserted += batch_count\n",
    "        print(f\"  Batch {start_idx//batch_size + 1}: Inserted {batch_count}/{len(batch)} records (Total: {records_inserted}/{total_records})\")\n",
    "    \n",
    "    cursor.close()\n",
    "    return records_inserted\n",
    "\n",
    "def insert_environmental_factors_batch(connection, environmental_df, batch_size=100):\n",
    "    \"\"\"Insert environmental factors in batches\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO environmental_factors \n",
    "    (student_id, parental_involvement, access_to_resources, extracurricular_activities,\n",
    "     sleep_hours, motivation_level, internet_access, family_income, teacher_quality,\n",
    "     school_type, peer_influence, physical_activity, parental_education_level)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    total_records = len(environmental_df)\n",
    "    records_inserted = 0\n",
    "    \n",
    "    print(f\"Inserting {total_records} environmental records in batches of {batch_size}...\")\n",
    "    \n",
    "    for start_idx in range(0, total_records, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_records)\n",
    "        batch = environmental_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        batch_count = 0\n",
    "        for _, row in batch.iterrows():\n",
    "            try:\n",
    "                cursor.execute(insert_query, (\n",
    "                    row['student_id'],\n",
    "                    row['parental_involvement'],\n",
    "                    row['access_to_resources'],\n",
    "                    row['extracurricular_activities'],\n",
    "                    row['sleep_hours'],\n",
    "                    row['motivation_level'],\n",
    "                    row['internet_access'],\n",
    "                    row['family_income'],\n",
    "                    row['teacher_quality'],\n",
    "                    row['school_type'],\n",
    "                    row['peer_influence'],\n",
    "                    row['physical_activity'],\n",
    "                    row['parental_education_level']\n",
    "                ))\n",
    "                batch_count += 1\n",
    "            except Error as e:\n",
    "                print(f\"  Error in row {start_idx + batch_count}: {e}\")\n",
    "        \n",
    "        connection.commit()\n",
    "        records_inserted += batch_count\n",
    "        print(f\"  Batch {start_idx//batch_size + 1}: Inserted {batch_count}/{len(batch)} records (Total: {records_inserted}/{total_records})\")\n",
    "    \n",
    "    cursor.close()\n",
    "    return records_inserted\n",
    "\n",
    "# Connect to database and insert data in batches\n",
    "try:\n",
    "    print(\"Connecting to MySQL database...\")\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MYSQL DATABASE POPULATION (BATCH MODE)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Insert students in batches of 100\n",
    "    print(\"\\n1. STUDENTS TABLE\")\n",
    "    print(\"-\" * 70)\n",
    "    students_count = insert_students_batch(connection, students_df, batch_size=100)\n",
    "    print(f\"✓ Total students inserted: {students_count}\")\n",
    "    \n",
    "    # Insert academic records in batches of 100\n",
    "    print(\"\\n2. ACADEMIC RECORDS TABLE\")\n",
    "    print(\"-\" * 70)\n",
    "    academic_count = insert_academic_records_batch(connection, academic_df, batch_size=100)\n",
    "    print(f\"✓ Total academic records inserted: {academic_count}\")\n",
    "    \n",
    "    # Insert environmental factors in batches of 100\n",
    "    print(\"\\n3. ENVIRONMENTAL FACTORS TABLE\")\n",
    "    print(\"-\" * 70)\n",
    "    env_count = insert_environmental_factors_batch(connection, environmental_df, batch_size=100)\n",
    "    print(f\"✓ Total environmental records inserted: {env_count}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DATABASE POPULATION COMPLETED!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total records inserted: {students_count + academic_count + env_count}\")\n",
    "    print(f\"  - Students: {students_count}\")\n",
    "    print(f\"  - Academic Records: {academic_count}\")\n",
    "    print(f\"  - Environmental Factors: {env_count}\")\n",
    "    \n",
    "    connection.close()\n",
    "    print(\"\\n✓ MySQL connection closed.\")\n",
    "    \n",
    "except Error as e:\n",
    "    print(f\"\\n✗ Error: {e}\")\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        connection.close()\n",
    "        print(\"MySQL connection closed due to error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFY DATABASE POPULATION\n",
    "\n",
    "def verify_database_population(connection):\n",
    "    \"\"\"Verify that data was inserted correctly\"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    print(\"DATABASE VERIFICATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check students table\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM students\")\n",
    "    student_count = cursor.fetchone()[0]\n",
    "    print(f\"\\nStudents Table: {student_count} records\")\n",
    "    \n",
    "    # Check academic_records table\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM academic_records\")\n",
    "    academic_count = cursor.fetchone()[0]\n",
    "    print(f\"Academic Records Table: {academic_count} records\")\n",
    "    \n",
    "    # Check environmental_factors table\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM environmental_factors\")\n",
    "    env_count = cursor.fetchone()[0]\n",
    "    print(f\"Environmental Factors Table: {env_count} records\")\n",
    "    \n",
    "    # Check predictions table\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM predictions\")\n",
    "    pred_count = cursor.fetchone()[0]\n",
    "    print(f\"Predictions Table: {pred_count} records (empty - will be populated by ML script)\")\n",
    "    \n",
    "    # Sample query - get first 3 students with all their data\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SAMPLE DATA - First 3 Complete Student Records:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        s.student_id,\n",
    "        s.gender,\n",
    "        s.learning_disabilities,\n",
    "        ar.hours_studied,\n",
    "        ar.attendance,\n",
    "        ar.exam_score,\n",
    "        ef.school_type,\n",
    "        ef.motivation_level\n",
    "    FROM students s\n",
    "    JOIN academic_records ar ON s.student_id = ar.student_id\n",
    "    JOIN environmental_factors ef ON s.student_id = ef.student_id\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    print(\"\\nStudent ID | Gender | Disabilities | Hours | Attendance | Score | School | Motivation\")\n",
    "    print(\"-\" * 90)\n",
    "    for row in results:\n",
    "        print(f\"{row[0]:10} | {row[1]:6} | {row[2]:12} | {row[3]:5} | {row[4]:10} | {row[5]:5} | {row[6]:6} | {row[7]}\")\n",
    "    \n",
    "    cursor.close()\n",
    "    \n",
    "    return {\n",
    "        'students': student_count,\n",
    "        'academic': academic_count,\n",
    "        'environmental': env_count,\n",
    "        'predictions': pred_count\n",
    "    }\n",
    "\n",
    "# Verify the data\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    counts = verify_database_population(connection)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VERIFICATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total Records in Database: {counts['students'] + counts['academic'] + counts['environmental']}\")\n",
    "    print(f\"Expected Records: {len(df) * 3}\")\n",
    "    print(f\"Status: {'SUCCESS' if counts['students'] == len(df) else 'INCOMPLETE'}\")\n",
    "    \n",
    "    connection.close()\n",
    "    \n",
    "except Error as e:\n",
    "    print(f\"Error during verification: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MYSQL ROLE COMPLETION CHECKLIST\n",
    "\n",
    "### ✅ Completed Tasks:\n",
    "1. **3NF Database Schema Design** - 4 tables with proper normalization\n",
    "2. **Primary & Foreign Keys** - All relationships defined\n",
    "3. **Stored Procedures** - 2 procedures created\n",
    "   - `GetStudentPerformanceSummary(student_id)` - Retrieves complete student data\n",
    "   - `InsertCompleteStudentRecord(...)` - Atomic multi-table insertion\n",
    "4. **Triggers** - 2 triggers implemented\n",
    "   - `audit_academic_records_update` - Logs all changes\n",
    "   - `validate_exam_score_insert` - Validates data before insertion\n",
    "5. **Database Population** - 6607 students across 3 tables (19,821 total records)\n",
    "6. **Data Verification** - Confirmed all records inserted correctly\n",
    "\n",
    "### 📋 Still TODO:\n",
    "1. **Create ERD Diagram** - Use dbdiagram.io or MySQL Workbench\n",
    "2. **Test Stored Procedures** - Execute and verify they work correctly\n",
    "3. **Test Triggers** - Verify audit logging and validation work\n",
    "4. **Create .env file** - Set up your MySQL credentials (see below)\n",
    "\n",
    "### 🔧 Environment Setup Instructions:\n",
    "\n",
    "Create a `.env` file in the project root with your MySQL credentials:\n",
    "\n",
    "```\n",
    "MYSQL_HOST=localhost\n",
    "MYSQL_PORT=3306\n",
    "MYSQL_USER=root\n",
    "MYSQL_PASSWORD=your_actual_password_here\n",
    "MYSQL_DATABASE=student_performance_db\n",
    "```\n",
    "\n",
    "**Note:** The `.env` file is already in `.gitignore` so your password won't be committed to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT STRUCTURE CREATED\n",
    "\n",
    "```\n",
    "Formative1_Database_predictionPipeline_group10/\n",
    "├── requirements.txt              # Dependencies\n",
    "├── .env.example                  # Environment template\n",
    "├── student_performance_db_schema.sql  # Complete MySQL schema\n",
    "├── app/\n",
    "│   ├── models/\n",
    "│   │   └── schemas.py           # Pydantic models for API\n",
    "│   ├── database/\n",
    "│   │   └── connection.py        # DB connections (MySQL + MongoDB)\n",
    "│   └── api/                     # FastAPI endpoints (next)\n",
    "├── models/                      # ML models storage\n",
    "└── Untitled8.ipynb             # This notebook\n",
    "```\n",
    "\n",
    "### Completed So Far:\n",
    "1. **Database Schema Design (3NF)** ✓\n",
    "2. **MySQL Tables with Constraints** ✓ \n",
    "3. **Stored Procedures & Triggers** ✓\n",
    "4. **Data Normalization** ✓\n",
    "5. **Project Structure** ✓\n",
    "6. **Pydantic Models** ✓\n",
    "7. **Database Connections** ✓\n",
    "\n",
    "### Next Steps:\n",
    "- FastAPI CRUD Endpoints\n",
    "- MongoDB Implementation  \n",
    "- ML Model Training\n",
    "- Prediction Script\n",
    "- Documentation & Testing"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
