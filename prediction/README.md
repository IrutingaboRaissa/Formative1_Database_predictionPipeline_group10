# Prediction Module

**Author:** Mitali  
**Purpose:** Fetch student data from API and make ML predictions

## ğŸ“‹ Overview

This module implements Task 3 of the assignment: Create a script to fetch data for prediction.

### Features:
1. âœ… Fetches latest student entry from database via API
2. âœ… Handles missing data and edge cases
3. âœ… Loads pre-trained ML model
4. âœ… Preprocesses data for prediction
5. âœ… Makes predictions using the model
6. âœ… Logs prediction results

## ğŸ“ Files

```
prediction/
â”œâ”€â”€ __init__.py              # Main prediction pipeline
â”œâ”€â”€ fetch_and_predict.py     # API data fetching and logging
â”œâ”€â”€ model_loader.py          # ML model loading and preprocessing
â””â”€â”€ README.md               # This file
```

## ğŸš€ Usage

### Prerequisites

1. **API must be running:**
   ```bash
   uvicorn app.main:app --reload
   ```

2. **Database must be populated with student data**

3. **ML model file** (optional - will use dummy model for testing)
   - Place your trained model in `models/student_performance_model.pkl`
   - Or `.joblib` format

### Run Prediction Pipeline

#### Option 1: Predict for latest student
```bash
python -m prediction
```

#### Option 2: Predict for specific student ID
```bash
python -m prediction 123
```

#### Option 3: Test individual components

**Test data fetching:**
```bash
python prediction/fetch_and_predict.py
```

**Test model loading:**
```bash
python prediction/model_loader.py
```

## ğŸ”§ Configuration

Edit `.env` file:
```env
API_BASE_URL=http://localhost:8000/api
```

## ğŸ“Š How It Works

### 1. Data Fetching (`fetch_and_predict.py`)

```python
fetcher = StudentDataFetcher()
student_data = fetcher.get_latest_student()
```

**API Endpoints Used:**
- `GET /api/students/` - Get all students
- `GET /api/students/{id}/complete/` - Get complete student data

### 2. Data Preprocessing (`model_loader.py`)

```python
preprocessor = DataPreprocessor()
df = preprocessor.prepare_features(student_data)
df = preprocessor.handle_missing_values(df)
df = preprocessor.encode_categorical_features(df)
```

**Features prepared:**
- Demographics: Gender, Learning Disabilities, Distance from Home
- Academic: Hours Studied, Attendance, Previous Scores, Tutoring Sessions
- Environmental: 13 factors (sleep, motivation, resources, etc.)

### 3. Model Prediction

```python
loader = ModelLoader()
loader.load_model()
predicted_score, confidence = loader.predict(student_data)
```

### 4. Logging Results

```python
logger = PredictionLogger()
logger.log_prediction(student_id, predicted_score, actual_score, confidence)
```

## ğŸ§ª Testing

### Test with Dummy Model

If you don't have a trained model yet:

```bash
python prediction/model_loader.py
```

This creates a simple RandomForest model for testing.

### Test API Connection

```bash
python prediction/fetch_and_predict.py
```

## ğŸ“ Adding Your ML Model

### From Intro to ML Course

1. **Export your trained model:**
   ```python
   import joblib
   joblib.dump(model, 'models/student_performance_model.pkl')
   ```

2. **Or use pickle:**
   ```python
   import pickle
   with open('models/student_performance_model.pkl', 'wb') as f:
       pickle.dump(model, f)
   ```

3. **Model requirements:**
   - Must accept 19 features
   - Should predict exam scores (0-110)
   - Can be any scikit-learn model (RandomForest, LinearRegression, etc.)

### Features Expected by Model

The model should expect these 19 features in order:
1. Gender (encoded)
2. Learning_Disabilities (encoded)
3. Distance_from_Home (encoded)
4. Hours_Studied
5. Attendance
6. Previous_Scores
7. Tutoring_Sessions
8. Parental_Involvement (encoded)
9. Access_to_Resources (encoded)
10. Extracurricular_Activities (encoded)
11. Sleep_Hours
12. Motivation_Level (encoded)
13. Internet_Access (encoded)
14. Family_Income (encoded)
15. Teacher_Quality (encoded)
16. School_Type (encoded)
17. Peer_Influence (encoded)
18. Physical_Activity
19. Parental_Education_Level (encoded)

## ğŸ› Error Handling

The pipeline handles:
- âœ… API connection failures
- âœ… Missing student data
- âœ… Model loading errors
- âœ… Missing feature values
- âœ… Invalid predictions
- âœ… Database logging failures

## ğŸ“ˆ Expected Output

```
======================================================================
STUDENT PERFORMANCE PREDICTION PIPELINE
======================================================================

[1/5] Checking API connection...
âœ“ API is running and accessible

[2/5] Fetching student data...
âœ“ Found latest student: ID 123
âœ“ Fetched complete data for student 123
âœ“ Fetched data for Student ID: 123

[3/5] Loading ML model...
âœ“ Model loaded successfully from models/student_performance_model.pkl

[4/5] Making prediction...
âœ“ Prediction completed successfully

[5/5] Logging prediction to database...

ğŸ“Š Prediction Result:
   Student ID: 123
   Predicted Score: 78.45
   Confidence: 0.8734
   Actual Score: 80

======================================================================
âœ… PREDICTION PIPELINE COMPLETED SUCCESSFULLY
======================================================================
```

## ğŸ¯ Assignment Requirements Met

- âœ… Fetch latest entry from database via API
- âœ… Load pre-trained ML model
- âœ… Preprocess data for prediction
- âœ… Make prediction using model
- âœ… Log prediction result back to database
- âœ… Handle missing data and edge cases

## ğŸ“š Dependencies

All dependencies are in `requirements.txt`:
```
requests==2.31.0
pandas==2.1.4
numpy==1.25.2
scikit-learn==1.3.2
joblib==1.3.2
python-dotenv==1.0.0
```

## ğŸ”— Related Files

- API Routes: `app/api/routes.py`
- Database Schema: `schema_ddl_only.sql`
- Requirements: `requirements.txt`

## ğŸ‘¥ Team Member

**Mitali** - Prediction Script Implementation

---

**Questions?** Check the main project README or ask in the group chat!
