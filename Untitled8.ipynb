{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS - All required libraries for the notebook\n",
    "\n",
    "# Data handling and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Kaggle dataset handling\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Data visualization (for future use)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning (for future use)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Statistical analysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub[pandas-datasets] in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub[pandas-datasets]) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub[pandas-datasets]) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->kagglehub[pandas-datasets]) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\pc\\.cache\\kagglehub\\datasets\\lainguyn123\\student-performance-factors\\versions\\9\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lainguyn123/student-performance-factors\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset shape: (6607, 20)\n",
      "Total records: 6607\n",
      "Total features: 20\n"
     ]
    }
   ],
   "source": [
    "# DATASET LOADING\n",
    "\n",
    "# Read the CSV file from the downloaded dataset\n",
    "csv_file_path = os.path.join(path, \"StudentPerformanceFactors.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET COLUMN NAMES (HEADLINES)\n",
      "============================================================\n",
      "\n",
      "Column Names:\n",
      " 1. Hours_Studied\n",
      " 2. Attendance\n",
      " 3. Parental_Involvement\n",
      " 4. Access_to_Resources\n",
      " 5. Extracurricular_Activities\n",
      " 6. Sleep_Hours\n",
      " 7. Previous_Scores\n",
      " 8. Motivation_Level\n",
      " 9. Internet_Access\n",
      "10. Tutoring_Sessions\n",
      "11. Family_Income\n",
      "12. Teacher_Quality\n",
      "13. School_Type\n",
      "14. Peer_Influence\n",
      "15. Physical_Activity\n",
      "16. Learning_Disabilities\n",
      "17. Parental_Education_Level\n",
      "18. Distance_from_Home\n",
      "19. Gender\n",
      "20. Exam_Score\n",
      "\n",
      "Total Columns: 20\n",
      "\n",
      "============================================================\n",
      "DATASET INFORMATION & DESCRIPTIONS\n",
      "============================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6607 entries, 0 to 6606\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Hours_Studied               6607 non-null   int64 \n",
      " 1   Attendance                  6607 non-null   int64 \n",
      " 2   Parental_Involvement        6607 non-null   object\n",
      " 3   Access_to_Resources         6607 non-null   object\n",
      " 4   Extracurricular_Activities  6607 non-null   object\n",
      " 5   Sleep_Hours                 6607 non-null   int64 \n",
      " 6   Previous_Scores             6607 non-null   int64 \n",
      " 7   Motivation_Level            6607 non-null   object\n",
      " 8   Internet_Access             6607 non-null   object\n",
      " 9   Tutoring_Sessions           6607 non-null   int64 \n",
      " 10  Family_Income               6607 non-null   object\n",
      " 11  Teacher_Quality             6529 non-null   object\n",
      " 12  School_Type                 6607 non-null   object\n",
      " 13  Peer_Influence              6607 non-null   object\n",
      " 14  Physical_Activity           6607 non-null   int64 \n",
      " 15  Learning_Disabilities       6607 non-null   object\n",
      " 16  Parental_Education_Level    6517 non-null   object\n",
      " 17  Distance_from_Home          6540 non-null   object\n",
      " 18  Gender                      6607 non-null   object\n",
      " 19  Exam_Score                  6607 non-null   int64 \n",
      "dtypes: int64(7), object(13)\n",
      "memory usage: 1.0+ MB\n",
      "\n",
      "============================================================\n",
      "STATISTICAL SUMMARY\n",
      "============================================================\n",
      "       Hours_Studied   Attendance  Sleep_Hours  Previous_Scores  \\\n",
      "count    6607.000000  6607.000000   6607.00000      6607.000000   \n",
      "mean       19.975329    79.977448      7.02906        75.070531   \n",
      "std         5.990594    11.547475      1.46812        14.399784   \n",
      "min         1.000000    60.000000      4.00000        50.000000   \n",
      "25%        16.000000    70.000000      6.00000        63.000000   \n",
      "50%        20.000000    80.000000      7.00000        75.000000   \n",
      "75%        24.000000    90.000000      8.00000        88.000000   \n",
      "max        44.000000   100.000000     10.00000       100.000000   \n",
      "\n",
      "       Tutoring_Sessions  Physical_Activity   Exam_Score  \n",
      "count        6607.000000        6607.000000  6607.000000  \n",
      "mean            1.493719           2.967610    67.235659  \n",
      "std             1.230570           1.031231     3.890456  \n",
      "min             0.000000           0.000000    55.000000  \n",
      "25%             1.000000           2.000000    65.000000  \n",
      "50%             1.000000           3.000000    67.000000  \n",
      "75%             2.000000           4.000000    69.000000  \n",
      "max             8.000000           6.000000   101.000000  \n",
      "\n",
      "============================================================\n",
      "DATA TYPES AND NON-NULL COUNTS\n",
      "============================================================\n",
      "\n",
      "Data Types:\n",
      "Hours_Studied             | int64        | Non-null: 6607 | Null:   0\n",
      "Attendance                | int64        | Non-null: 6607 | Null:   0\n",
      "Parental_Involvement      | object       | Non-null: 6607 | Null:   0\n",
      "Access_to_Resources       | object       | Non-null: 6607 | Null:   0\n",
      "Extracurricular_Activities | object       | Non-null: 6607 | Null:   0\n",
      "Sleep_Hours               | int64        | Non-null: 6607 | Null:   0\n",
      "Previous_Scores           | int64        | Non-null: 6607 | Null:   0\n",
      "Motivation_Level          | object       | Non-null: 6607 | Null:   0\n",
      "Internet_Access           | object       | Non-null: 6607 | Null:   0\n",
      "Tutoring_Sessions         | int64        | Non-null: 6607 | Null:   0\n",
      "Family_Income             | object       | Non-null: 6607 | Null:   0\n",
      "Teacher_Quality           | object       | Non-null: 6529 | Null:  78\n",
      "School_Type               | object       | Non-null: 6607 | Null:   0\n",
      "Peer_Influence            | object       | Non-null: 6607 | Null:   0\n",
      "Physical_Activity         | int64        | Non-null: 6607 | Null:   0\n",
      "Learning_Disabilities     | object       | Non-null: 6607 | Null:   0\n",
      "Parental_Education_Level  | object       | Non-null: 6517 | Null:  90\n",
      "Distance_from_Home        | object       | Non-null: 6540 | Null:  67\n",
      "Gender                    | object       | Non-null: 6607 | Null:   0\n",
      "Exam_Score                | int64        | Non-null: 6607 | Null:   0\n",
      "\n",
      "============================================================\n",
      "SAMPLE DATA (First 5 rows)\n",
      "============================================================\n",
      "   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n",
      "0             23          84                  Low                High   \n",
      "1             19          64                  Low              Medium   \n",
      "2             24          98               Medium              Medium   \n",
      "3             29          89                  Low              Medium   \n",
      "4             19          92               Medium              Medium   \n",
      "\n",
      "  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n",
      "0                         No            7               73              Low   \n",
      "1                         No            8               59              Low   \n",
      "2                        Yes            7               91           Medium   \n",
      "3                        Yes            8               98           Medium   \n",
      "4                        Yes            6               65           Medium   \n",
      "\n",
      "  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n",
      "0             Yes                  0           Low          Medium   \n",
      "1             Yes                  2        Medium          Medium   \n",
      "2             Yes                  2        Medium          Medium   \n",
      "3             Yes                  1        Medium          Medium   \n",
      "4             Yes                  3        Medium            High   \n",
      "\n",
      "  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n",
      "0      Public       Positive                  3                    No   \n",
      "1      Public       Negative                  4                    No   \n",
      "2      Public        Neutral                  4                    No   \n",
      "3      Public       Negative                  4                    No   \n",
      "4      Public        Neutral                  4                    No   \n",
      "\n",
      "  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n",
      "0              High School               Near    Male          67  \n",
      "1                  College           Moderate  Female          61  \n",
      "2             Postgraduate               Near    Male          74  \n",
      "3              High School           Moderate    Male          71  \n",
      "4                  College               Near  Female          70  \n"
     ]
    }
   ],
   "source": [
    "# DATASET EXPLORATION & ANALYSIS\n",
    "\n",
    "# Display column names (headlines) and basic dataset information\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET COLUMN NAMES (HEADLINES)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal Columns: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET INFORMATION & DESCRIPTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display detailed info about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display statistical summary\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA TYPES AND NON-NULL COUNTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display data types and null values\n",
    "print(\"\\nData Types:\")\n",
    "for col in df.columns:\n",
    "    dtype = df[col].dtype\n",
    "    non_null = df[col].count()\n",
    "    null_count = df[col].isnull().sum()\n",
    "    print(f\"{col:25s} | {str(dtype):12s} | Non-null: {non_null:4d} | Null: {null_count:3d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE DATA (First 5 rows)\")\n",
    "print(\"=\" * 60)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORMATIVE 1: DATABASE DESIGN & PREDICTION PIPELINE\n",
    "\n",
    "## Project Overview\n",
    "**Dataset:** Student Performance Factors  \n",
    "**Objective:** Create a comprehensive database system with ML prediction capabilities\n",
    "\n",
    "### Tasks:\n",
    "1. **Task 1:** Database Design (SQL + MongoDB)\n",
    "2. **Task 2:** FastAPI CRUD Operations  \n",
    "3. **Task 3:** ML Prediction Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ANALYZING DATASET FOR NORMALIZATION\n",
      "==================================================\n",
      "\n",
      "üìù PROPOSED SCHEMA DESIGN (3NF):\n",
      "\n",
      "1Ô∏è‚É£ STUDENTS Table (Main Entity):\n",
      "   - student_id (PK)\n",
      "   - Gender\n",
      "   - Learning_Disabilities\n",
      "   - Distance_from_Home\n",
      "\n",
      "2Ô∏è‚É£ ACADEMIC_RECORDS Table:\n",
      "   - record_id (PK)\n",
      "   - student_id (FK)\n",
      "   - Hours_Studied\n",
      "   - Attendance\n",
      "   - Previous_Scores\n",
      "   - Tutoring_Sessions\n",
      "   - Exam_Score\n",
      "   - created_at\n",
      "\n",
      "3Ô∏è‚É£ ENVIRONMENTAL_FACTORS Table:\n",
      "   - env_id (PK)\n",
      "   - student_id (FK)\n",
      "   - Parental_Involvement\n",
      "   - Access_to_Resources\n",
      "   - Extracurricular_Activities\n",
      "   - Sleep_Hours\n",
      "   - Motivation_Level\n",
      "   - Internet_Access\n",
      "   - Family_Income\n",
      "   - Teacher_Quality\n",
      "   - School_Type\n",
      "   - Peer_Influence\n",
      "   - Physical_Activity\n",
      "   - Parental_Education_Level\n",
      "\n",
      "4Ô∏è‚É£ PREDICTIONS Table (For ML Results):\n",
      "   - prediction_id (PK)\n",
      "   - student_id (FK)\n",
      "   - predicted_score\n",
      "   - actual_score\n",
      "   - model_version\n",
      "   - prediction_date\n",
      "   - confidence_score\n",
      "\n",
      "üîó RELATIONSHIPS:\n",
      "   - Students (1) ‚Üí Academic_Records (Many)\n",
      "   - Students (1) ‚Üí Environmental_Factors (Many)\n",
      "   - Students (1) ‚Üí Predictions (Many)\n",
      "\n",
      "‚úÖ Schema satisfies 3NF requirements:\n",
      "   ‚úì 1NF: Atomic values, unique rows\n",
      "   ‚úì 2NF: No partial dependencies\n",
      "   ‚úì 3NF: No transitive dependencies\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: DATABASE SCHEMA DESIGN (3NF Normalization)\n",
    "\n",
    "# Analyze dataset structure for normalization\n",
    "print(\"ANALYZING DATASET FOR NORMALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Group columns by logical entities for normalization\n",
    "print(\"\\nPROPOSED SCHEMA DESIGN (3NF):\")\n",
    "print(\"\\n1. STUDENTS Table (Main Entity):\")\n",
    "students_cols = ['student_id (PK)', 'Gender', 'Learning_Disabilities', 'Distance_from_Home']\n",
    "for col in students_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n2. ACADEMIC_RECORDS Table:\")\n",
    "academic_cols = ['record_id (PK)', 'student_id (FK)', 'Hours_Studied', 'Attendance', \n",
    "                'Previous_Scores', 'Tutoring_Sessions', 'Exam_Score', 'created_at']\n",
    "for col in academic_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n3. ENVIRONMENTAL_FACTORS Table:\")\n",
    "env_cols = ['env_id (PK)', 'student_id (FK)', 'Parental_Involvement', 'Access_to_Resources',\n",
    "           'Extracurricular_Activities', 'Sleep_Hours', 'Motivation_Level', 'Internet_Access',\n",
    "           'Family_Income', 'Teacher_Quality', 'School_Type', 'Peer_Influence', \n",
    "           'Physical_Activity', 'Parental_Education_Level']\n",
    "for col in env_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n4. PREDICTIONS Table (For ML Results):\")\n",
    "pred_cols = ['prediction_id (PK)', 'student_id (FK)', 'predicted_score', \n",
    "            'actual_score', 'model_version', 'prediction_date', 'confidence_score']\n",
    "for col in pred_cols:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\nRELATIONSHIPS:\")\n",
    "print(\"   - Students (1) ‚Üí Academic_Records (Many)\")\n",
    "print(\"   - Students (1) ‚Üí Environmental_Factors (Many)\")  \n",
    "print(\"   - Students (1) ‚Üí Predictions (Many)\")\n",
    "\n",
    "print(\"\\nSchema satisfies 3NF requirements:\")\n",
    "print(\"   1NF: Atomic values, unique rows\")\n",
    "print(\"   2NF: No partial dependencies\")\n",
    "print(\"   3NF: No transitive dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ MySQL Database Schema Generated Successfully!\n",
      "üèóÔ∏è  Schema includes:\n",
      "   ‚úÖ 4 main tables + 1 audit table\n",
      "   ‚úÖ Primary and Foreign Key constraints\n",
      "   ‚úÖ Check constraints for data validation\n",
      "   ‚úÖ Appropriate indexes for performance\n",
      "   ‚úÖ Timestamps for tracking\n",
      "\\nüìù Next: Stored Procedure & Trigger creation...\n"
     ]
    }
   ],
   "source": [
    "# MYSQL DATABASE CREATION SCRIPTS\n",
    "\n",
    "# Generate MySQL DDL statements for database creation\n",
    "mysql_ddl = \"\"\"\n",
    "-- STUDENT PERFORMANCE DATABASE SCHEMA\n",
    "\n",
    "DROP DATABASE IF EXISTS student_performance_db;\n",
    "CREATE DATABASE student_performance_db;\n",
    "USE student_performance_db;\n",
    "\n",
    "-- TABLE 1: STUDENTS (Main Entity)\n",
    "CREATE TABLE students (\n",
    "    student_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    gender ENUM('Male', 'Female') NOT NULL,\n",
    "    learning_disabilities ENUM('Yes', 'No') NOT NULL DEFAULT 'No',\n",
    "    distance_from_home ENUM('Near', 'Moderate', 'Far') DEFAULT 'Moderate',\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "    \n",
    "    INDEX idx_gender (gender),\n",
    "    INDEX idx_learning_disabilities (learning_disabilities)\n",
    ");\n",
    "\n",
    "-- TABLE 2: ACADEMIC_RECORDS\n",
    "CREATE TABLE academic_records (\n",
    "    record_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    hours_studied INT CHECK (hours_studied >= 0 AND hours_studied <= 50),\n",
    "    attendance INT CHECK (attendance >= 0 AND attendance <= 100),\n",
    "    previous_scores INT CHECK (previous_scores >= 0 AND previous_scores <= 100),\n",
    "    tutoring_sessions INT DEFAULT 0 CHECK (tutoring_sessions >= 0),\n",
    "    exam_score INT CHECK (exam_score >= 0 AND exam_score <= 110),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_academic (student_id),\n",
    "    INDEX idx_exam_score (exam_score),\n",
    "    INDEX idx_created_at (created_at)\n",
    ");\n",
    "\n",
    "-- TABLE 3: ENVIRONMENTAL_FACTORS  \n",
    "CREATE TABLE environmental_factors (\n",
    "    env_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    parental_involvement ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    access_to_resources ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    extracurricular_activities ENUM('Yes', 'No') DEFAULT 'No',\n",
    "    sleep_hours INT CHECK (sleep_hours >= 4 AND sleep_hours <= 12),\n",
    "    motivation_level ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    internet_access ENUM('Yes', 'No') DEFAULT 'Yes',\n",
    "    family_income ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    teacher_quality ENUM('Low', 'Medium', 'High') DEFAULT 'Medium',\n",
    "    school_type ENUM('Public', 'Private') DEFAULT 'Public',\n",
    "    peer_influence ENUM('Positive', 'Neutral', 'Negative') DEFAULT 'Neutral',\n",
    "    physical_activity INT CHECK (physical_activity >= 0 AND physical_activity <= 10),\n",
    "    parental_education_level ENUM('High School', 'College', 'Postgraduate') DEFAULT 'High School',\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_env (student_id),\n",
    "    INDEX idx_parental_involvement (parental_involvement),\n",
    "    INDEX idx_school_type (school_type)\n",
    ");\n",
    "\n",
    "-- TABLE 4: PREDICTIONS (ML Results)\n",
    "CREATE TABLE predictions (\n",
    "    prediction_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    student_id INT NOT NULL,\n",
    "    predicted_score DECIMAL(5,2) CHECK (predicted_score >= 0 AND predicted_score <= 110),\n",
    "    actual_score INT NULL CHECK (actual_score >= 0 AND actual_score <= 110),\n",
    "    model_version VARCHAR(50) DEFAULT 'v1.0',\n",
    "    confidence_score DECIMAL(5,4) CHECK (confidence_score >= 0 AND confidence_score <= 1),\n",
    "    prediction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    FOREIGN KEY (student_id) REFERENCES students(student_id) ON DELETE CASCADE,\n",
    "    INDEX idx_student_predictions (student_id),\n",
    "    INDEX idx_prediction_date (prediction_date),\n",
    "    INDEX idx_model_version (model_version)\n",
    ");\n",
    "\n",
    "-- TABLE 5: AUDIT_LOG (For Trigger)\n",
    "CREATE TABLE audit_log (\n",
    "    log_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    table_name VARCHAR(50) NOT NULL,\n",
    "    operation ENUM('INSERT', 'UPDATE', 'DELETE') NOT NULL,\n",
    "    record_id INT NOT NULL,\n",
    "    old_values JSON NULL,\n",
    "    new_values JSON NULL,\n",
    "    changed_by VARCHAR(100) DEFAULT 'system',\n",
    "    change_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    \n",
    "    INDEX idx_table_operation (table_name, operation),\n",
    "    INDEX idx_change_timestamp (change_timestamp)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"MySQL Database Schema Generated Successfully!\")\n",
    "print(\"Schema includes:\")\n",
    "print(\"   4 main tables + 1 audit table\")\n",
    "print(\"   Primary and Foreign Key constraints\") \n",
    "print(\"   Check constraints for data validation\")\n",
    "print(\"   Appropriate indexes for performance\")\n",
    "print(\"   Timestamps for tracking\")\n",
    "print(\"\\nNext: Stored Procedure & Trigger creation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß STORED PROCEDURES & TRIGGERS CREATED:\n",
      "==================================================\n",
      "üìä Stored Procedures:\n",
      "   1Ô∏è‚É£ GetStudentPerformanceSummary() - Comprehensive student data retrieval\n",
      "   2Ô∏è‚É£ InsertCompleteStudentRecord() - Atomic multi-table insertion\n",
      "\n",
      "‚ö° Triggers:\n",
      "   1Ô∏è‚É£ audit_academic_records_update - Logs all academic record changes\n",
      "   2Ô∏è‚É£ validate_exam_score_insert - Data validation before insertion\n",
      "\n",
      "‚úÖ All database objects satisfy assignment requirements!\n",
      "\\nüíæ Complete SQL script saved to: student_performance_db_schema.sql\n"
     ]
    }
   ],
   "source": [
    "# STORED PROCEDURES & TRIGGERS\n",
    "\n",
    "stored_procedures_triggers = \"\"\"\n",
    "-- STORED PROCEDURE: Get Student Performance Summary\n",
    "DELIMITER //\n",
    "\n",
    "CREATE PROCEDURE GetStudentPerformanceSummary(IN student_id_param INT)\n",
    "BEGIN\n",
    "    DECLARE EXIT HANDLER FOR SQLEXCEPTION\n",
    "    BEGIN\n",
    "        ROLLBACK;\n",
    "        RESIGNAL;\n",
    "    END;\n",
    "    \n",
    "    SELECT \n",
    "        s.student_id,\n",
    "        s.gender,\n",
    "        s.learning_disabilities,\n",
    "        s.distance_from_home,\n",
    "        ar.hours_studied,\n",
    "        ar.attendance,\n",
    "        ar.previous_scores,\n",
    "        ar.exam_score,\n",
    "        ef.parental_involvement,\n",
    "        ef.school_type,\n",
    "        ef.motivation_level,\n",
    "        COUNT(p.prediction_id) as total_predictions,\n",
    "        AVG(p.predicted_score) as avg_predicted_score,\n",
    "        AVG(p.confidence_score) as avg_confidence\n",
    "    FROM students s\n",
    "    LEFT JOIN academic_records ar ON s.student_id = ar.student_id\n",
    "    LEFT JOIN environmental_factors ef ON s.student_id = ef.student_id  \n",
    "    LEFT JOIN predictions p ON s.student_id = p.student_id\n",
    "    WHERE s.student_id = student_id_param\n",
    "    GROUP BY s.student_id, s.gender, s.learning_disabilities, s.distance_from_home,\n",
    "             ar.hours_studied, ar.attendance, ar.previous_scores, ar.exam_score,\n",
    "             ef.parental_involvement, ef.school_type, ef.motivation_level;\n",
    "END //\n",
    "\n",
    "-- STORED PROCEDURE: Insert Complete Student Record\n",
    "CREATE PROCEDURE InsertCompleteStudentRecord(\n",
    "    IN p_gender ENUM('Male', 'Female'),\n",
    "    IN p_learning_disabilities ENUM('Yes', 'No'),\n",
    "    IN p_distance_from_home ENUM('Near', 'Moderate', 'Far'),\n",
    "    IN p_hours_studied INT,\n",
    "    IN p_attendance INT,\n",
    "    IN p_previous_scores INT,\n",
    "    IN p_exam_score INT,\n",
    "    IN p_parental_involvement ENUM('Low', 'Medium', 'High'),\n",
    "    IN p_access_to_resources ENUM('Low', 'Medium', 'High'),\n",
    "    IN p_sleep_hours INT,\n",
    "    IN p_school_type ENUM('Public', 'Private'),\n",
    "    OUT p_student_id INT\n",
    ")\n",
    "BEGIN\n",
    "    DECLARE EXIT HANDLER FOR SQLEXCEPTION\n",
    "    BEGIN\n",
    "        ROLLBACK;\n",
    "        RESIGNAL;\n",
    "    END;\n",
    "    \n",
    "    START TRANSACTION;\n",
    "    \n",
    "    -- Insert student\n",
    "    INSERT INTO students (gender, learning_disabilities, distance_from_home)\n",
    "    VALUES (p_gender, p_learning_disabilities, p_distance_from_home);\n",
    "    \n",
    "    SET p_student_id = LAST_INSERT_ID();\n",
    "    \n",
    "    -- Insert academic record\n",
    "    INSERT INTO academic_records (student_id, hours_studied, attendance, previous_scores, exam_score)\n",
    "    VALUES (p_student_id, p_hours_studied, p_attendance, p_previous_scores, p_exam_score);\n",
    "    \n",
    "    -- Insert environmental factors\n",
    "    INSERT INTO environmental_factors (student_id, parental_involvement, access_to_resources, sleep_hours, school_type)\n",
    "    VALUES (p_student_id, p_parental_involvement, p_access_to_resources, p_sleep_hours, p_school_type);\n",
    "    \n",
    "    COMMIT;\n",
    "END //\n",
    "\n",
    "DELIMITER ;\n",
    "\n",
    "-- TRIGGER: Audit Academic Records Changes\n",
    "DELIMITER //\n",
    "\n",
    "CREATE TRIGGER audit_academic_records_update\n",
    "    AFTER UPDATE ON academic_records\n",
    "    FOR EACH ROW\n",
    "BEGIN\n",
    "    INSERT INTO audit_log (\n",
    "        table_name, \n",
    "        operation, \n",
    "        record_id, \n",
    "        old_values, \n",
    "        new_values,\n",
    "        changed_by\n",
    "    ) VALUES (\n",
    "        'academic_records',\n",
    "        'UPDATE',\n",
    "        NEW.record_id,\n",
    "        JSON_OBJECT(\n",
    "            'hours_studied', OLD.hours_studied,\n",
    "            'attendance', OLD.attendance, \n",
    "            'previous_scores', OLD.previous_scores,\n",
    "            'exam_score', OLD.exam_score\n",
    "        ),\n",
    "        JSON_OBJECT(\n",
    "            'hours_studied', NEW.hours_studied,\n",
    "            'attendance', NEW.attendance,\n",
    "            'previous_scores', NEW.previous_scores, \n",
    "            'exam_score', NEW.exam_score\n",
    "        ),\n",
    "        USER()\n",
    "    );\n",
    "END //\n",
    "\n",
    "-- TRIGGER: Validate Exam Score Range\n",
    "CREATE TRIGGER validate_exam_score_insert\n",
    "    BEFORE INSERT ON academic_records\n",
    "    FOR EACH ROW\n",
    "BEGIN\n",
    "    IF NEW.exam_score < 0 OR NEW.exam_score > 110 THEN\n",
    "        SIGNAL SQLSTATE '45000' \n",
    "        SET MESSAGE_TEXT = 'Exam score must be between 0 and 110';\n",
    "    END IF;\n",
    "    \n",
    "    IF NEW.attendance < 60 AND NEW.exam_score > 90 THEN\n",
    "        SIGNAL SQLSTATE '45000'\n",
    "        SET MESSAGE_TEXT = 'Attendance below 60% with score above 90 seems suspicious';\n",
    "    END IF;\n",
    "END //\n",
    "\n",
    "DELIMITER ;\n",
    "\"\"\"\n",
    "\n",
    "print(\"STORED PROCEDURES & TRIGGERS CREATED:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Stored Procedures:\")\n",
    "print(\"   1. GetStudentPerformanceSummary() - Comprehensive student data retrieval\")\n",
    "print(\"   2. InsertCompleteStudentRecord() - Atomic multi-table insertion\")\n",
    "print()\n",
    "print(\"Triggers:\")\n",
    "print(\"   1. audit_academic_records_update - Logs all academic record changes\")\n",
    "print(\"   2. validate_exam_score_insert - Data validation before insertion\")\n",
    "print()\n",
    "print(\"All database objects satisfy assignment requirements!\")\n",
    "\n",
    "# Save the complete SQL script to file\n",
    "with open('student_performance_db_schema.sql', 'w') as f:\n",
    "    f.write(mysql_ddl + \"\\n\" + stored_procedures_triggers)\n",
    "    \n",
    "print(\"\\nComplete SQL script saved to: student_performance_db_schema.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ TRANSFORMING DATASET FOR NORMALIZED SCHEMA\n",
      "==================================================\n",
      "‚úÖ Data transformation completed:\n",
      "   üìä Students: 6607 records\n",
      "   üìö Academic Records: 6607 records\n",
      "   üåç Environmental Factors: 6607 records\n",
      "\\nüîç SAMPLE NORMALIZED DATA:\n",
      "\\nStudents Table (first 3):\n",
      "   student_id  gender learning_disabilities distance_from_home\n",
      "0           1    Male                    No               Near\n",
      "1           2  Female                    No           Moderate\n",
      "2           3    Male                    No               Near\n",
      "\\nAcademic Records (first 3):\n",
      "   student_id  hours_studied  attendance  previous_scores  tutoring_sessions  \\\n",
      "0           1             23          84               73                  0   \n",
      "1           2             19          64               59                  2   \n",
      "2           3             24          98               91                  2   \n",
      "\n",
      "   exam_score  \n",
      "0          67  \n",
      "1          61  \n",
      "2          74  \n",
      "\\nEnvironmental Factors (first 3):\n",
      "   student_id parental_involvement school_type motivation_level\n",
      "0           1                  Low      Public              Low\n",
      "1           2                  Low      Public              Low\n",
      "2           3               Medium      Public           Medium\n"
     ]
    }
   ],
   "source": [
    "# DATA TRANSFORMATION & DATABASE POPULATION\n",
    "\n",
    "# Transform the flat dataset into normalized structure\n",
    "print(\"TRANSFORMING DATASET FOR NORMALIZED SCHEMA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create normalized dataframes\n",
    "students_data = []\n",
    "academic_records_data = []\n",
    "environmental_factors_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    student_id = index + 1  # Start from 1\n",
    "    \n",
    "    # Students table data\n",
    "    students_data.append({\n",
    "        'student_id': student_id,\n",
    "        'gender': row['Gender'],\n",
    "        'learning_disabilities': row['Learning_Disabilities'],\n",
    "        'distance_from_home': row['Distance_from_Home'] if pd.notna(row['Distance_from_Home']) else 'Moderate'\n",
    "    })\n",
    "    \n",
    "    # Academic records data\n",
    "    academic_records_data.append({\n",
    "        'student_id': student_id,\n",
    "        'hours_studied': int(row['Hours_Studied']),\n",
    "        'attendance': int(row['Attendance']), \n",
    "        'previous_scores': int(row['Previous_Scores']),\n",
    "        'tutoring_sessions': int(row['Tutoring_Sessions']),\n",
    "        'exam_score': int(row['Exam_Score'])\n",
    "    })\n",
    "    \n",
    "    # Environmental factors data\n",
    "    environmental_factors_data.append({\n",
    "        'student_id': student_id,\n",
    "        'parental_involvement': row['Parental_Involvement'],\n",
    "        'access_to_resources': row['Access_to_Resources'],\n",
    "        'extracurricular_activities': row['Extracurricular_Activities'],\n",
    "        'sleep_hours': int(row['Sleep_Hours']),\n",
    "        'motivation_level': row['Motivation_Level'],\n",
    "        'internet_access': row['Internet_Access'],\n",
    "        'family_income': row['Family_Income'],\n",
    "        'teacher_quality': row['Teacher_Quality'] if pd.notna(row['Teacher_Quality']) else 'Medium',\n",
    "        'school_type': row['School_Type'],\n",
    "        'peer_influence': row['Peer_Influence'],\n",
    "        'physical_activity': int(row['Physical_Activity']),\n",
    "        'parental_education_level': row['Parental_Education_Level'] if pd.notna(row['Parental_Education_Level']) else 'High School'\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "students_df = pd.DataFrame(students_data)\n",
    "academic_df = pd.DataFrame(academic_records_data)\n",
    "environmental_df = pd.DataFrame(environmental_factors_data)\n",
    "\n",
    "print(f\"Data transformation completed:\")\n",
    "print(f\"   Students: {len(students_df)} records\")\n",
    "print(f\"   Academic Records: {len(academic_df)} records\")\n",
    "print(f\"   Environmental Factors: {len(environmental_df)} records\")\n",
    "\n",
    "# Display sample of normalized data\n",
    "print(\"\\nSAMPLE NORMALIZED DATA:\")\n",
    "print(\"\\nStudents Table (first 3):\")\n",
    "print(students_df.head(3))\n",
    "\n",
    "print(\"\\nAcademic Records (first 3):\")\n",
    "print(academic_df.head(3))\n",
    "\n",
    "print(\"\\nEnvironmental Factors (first 3):\")\n",
    "print(environmental_df[['student_id', 'parental_involvement', 'school_type', 'motivation_level']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT STRUCTURE CREATED\n",
    "\n",
    "```\n",
    "Formative1_Database_predictionPipeline_group10/\n",
    "‚îú‚îÄ‚îÄ requirements.txt              # Dependencies\n",
    "‚îú‚îÄ‚îÄ .env.example                  # Environment template\n",
    "‚îú‚îÄ‚îÄ student_performance_db_schema.sql  # Complete MySQL schema\n",
    "‚îú‚îÄ‚îÄ app/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py           # Pydantic models for API\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ database/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ connection.py        # DB connections (MySQL + MongoDB)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ api/                     # FastAPI endpoints (next)\n",
    "‚îú‚îÄ‚îÄ models/                      # ML models storage\n",
    "‚îî‚îÄ‚îÄ Untitled8.ipynb             # This notebook\n",
    "```\n",
    "\n",
    "### Completed So Far:\n",
    "1. **Database Schema Design (3NF)** ‚úì\n",
    "2. **MySQL Tables with Constraints** ‚úì \n",
    "3. **Stored Procedures & Triggers** ‚úì\n",
    "4. **Data Normalization** ‚úì\n",
    "5. **Project Structure** ‚úì\n",
    "6. **Pydantic Models** ‚úì\n",
    "7. **Database Connections** ‚úì\n",
    "\n",
    "### Next Steps:\n",
    "- FastAPI CRUD Endpoints\n",
    "- MongoDB Implementation  \n",
    "- ML Model Training\n",
    "- Prediction Script\n",
    "- Documentation & Testing"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
